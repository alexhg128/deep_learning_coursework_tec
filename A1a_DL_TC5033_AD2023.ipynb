{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 1a: Implementing a Multilayer Fully Connected Network using Numpy\n",
    "#### Non-graded activity (0 points)\n",
    "\n",
    "- Objective\n",
    "\n",
    "The primary objective of this activity is to deepen your understanding of Fully Connected Networks by implementing a multilayer network using only Numpy. You  are  given  the follosing starter code that solves the MNIST dataset problem. Your task is to read, understand, and then apply this knowledge to solve classification problems on other datasets such as the Kaggle ASL dataset (Starter code will be provided separately for that activity).\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    Read and Understand the following Code: The provided starter code outlines the architecture of a Fully Connected Network designed to classify MNIST images. Go through the code to understand how each function and class is used to implement the network.\n",
    "\n",
    "    Understand the Math: Make sure you understand the math operations implemented in the code, especially during the forward and backward passes. This will involve matrix multiplications, activation functions, loss computations, and backpropagation.\n",
    "    \n",
    "- Experiment\n",
    "    You are encouraged to play with the code, change any hyperparameters and train the model, you should be able to achieve over 95% accuracy on the test set without problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:20:48.224315Z",
     "start_time": "2023-10-01T05:20:47.770469Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T05:20:52.109212Z",
     "start_time": "2023-10-01T05:20:52.104768Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T06:06:45.767739Z",
     "start_time": "2023-10-01T06:06:45.720661Z"
    }
   },
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'\\x00\\x00')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadGzipFile\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# MNIST path\u001B[39;00m\n\u001B[1;32m      2\u001B[0m mnist_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./mnist_raw/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 3\u001B[0m x_train_num, y_train_num, x_test_num, y_test_num \u001B[38;5;241m=\u001B[39m get_images(mnist_path)\n\u001B[1;32m      5\u001B[0m x_train \u001B[38;5;241m=\u001B[39m x_train_num[:\u001B[38;5;241m50000\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m50000\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n\u001B[1;32m      6\u001B[0m y_train \u001B[38;5;241m=\u001B[39m y_train_num[:\u001B[38;5;241m50000\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m50000\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Code/TC_5033_course/get_images.py:22\u001B[0m, in \u001B[0;36mget_images\u001B[0;34m(mnist_path)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain-labels\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m gzip\u001B[38;5;241m.\u001B[39mopen(f, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m data:\n\u001B[0;32m---> 22\u001B[0m         train_labels \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mread()[\u001B[38;5;241m8\u001B[39m:]\n\u001B[1;32m     23\u001B[0m         y_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfrombuffer(train_labels, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39muint8)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt10k-images\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m f:\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/gzip.py:301\u001B[0m, in \u001B[0;36mGzipFile.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01merrno\u001B[39;00m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mEBADF, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread() on write-only GzipFile object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 301\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer\u001B[38;5;241m.\u001B[39mread(size)\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/_compression.py:118\u001B[0m, in \u001B[0;36mDecompressReader.readall\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    114\u001B[0m chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    115\u001B[0m \u001B[38;5;66;03m# sys.maxsize means the max length of output buffer is unlimited,\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;66;03m# so that the whole input buffer can be decompressed within one\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m# .decompress() call.\u001B[39;00m\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m data \u001B[38;5;241m:=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(sys\u001B[38;5;241m.\u001B[39mmaxsize):\n\u001B[1;32m    119\u001B[0m     chunks\u001B[38;5;241m.\u001B[39mappend(data)\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(chunks)\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/gzip.py:499\u001B[0m, in \u001B[0;36m_GzipReader.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new_member:\n\u001B[1;32m    496\u001B[0m     \u001B[38;5;66;03m# If the _new_member flag is set, we have to\u001B[39;00m\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# jump to the next member, if there is one.\u001B[39;00m\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_read()\n\u001B[0;32m--> 499\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_gzip_header():\n\u001B[1;32m    500\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos\n\u001B[1;32m    501\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/gzip.py:468\u001B[0m, in \u001B[0;36m_GzipReader._read_gzip_header\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_gzip_header\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 468\u001B[0m     last_mtime \u001B[38;5;241m=\u001B[39m _read_gzip_header(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp)\n\u001B[1;32m    469\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m last_mtime \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    470\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/gzip.py:428\u001B[0m, in \u001B[0;36m_read_gzip_header\u001B[0;34m(fp)\u001B[0m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m magic \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\037\u001B[39;00m\u001B[38;5;130;01m\\213\u001B[39;00m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 428\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BadGzipFile(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNot a gzipped file (\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m magic)\n\u001B[1;32m    430\u001B[0m (method, flag, last_mtime) \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39munpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BBIxx\u001B[39m\u001B[38;5;124m\"\u001B[39m, _read_exact(fp, \u001B[38;5;241m8\u001B[39m))\n\u001B[1;32m    431\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m8\u001B[39m:\n",
      "\u001B[0;31mBadGzipFile\u001B[0m: Not a gzipped file (b'\\x00\\x00')"
     ]
    }
   ],
   "source": [
    "# MNIST path\n",
    "mnist_path = './mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(float)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(float)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(float)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0])\n",
    "b = a.view(np_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    # Costo\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    # Calcular gradientes\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def accuracy(x, y, mb_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
    "mb_size = 512\n",
    "learning_rate = 1e-4\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(x_test, y_test, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}, el valor real es:{y_test[idx][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
