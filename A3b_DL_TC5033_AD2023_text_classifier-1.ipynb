{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940c6dbc",
   "metadata": {},
   "source": [
    "## TC 5033\n",
    "### Word Embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Activity 3b: Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
    "<br>\n",
    "\n",
    "- Objective:\n",
    "    - Understand the basics of Recurrent Neural Networks (RNNs) and their application in text classification.\n",
    "    - Learn how to handle a real-world text dataset, AG_NEWS, in PyTorch.\n",
    "    - Gain hands-on experience in defining, training, and evaluating a text classification model in PyTorch.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Instructions:\n",
    "    - Data Preparation: Starter code will be provided that loads the AG_NEWS dataset and prepares it for training. Do not modify this part. However, you should be sure to understand it, and comment it, the use of markdown cells is suggested. \n",
    "\n",
    "    - Model Setup: A skeleton code for the RNN model class will be provided. Complete this class and use it to instantiate your model.\n",
    "\n",
    "    - Implementing Accuracy Function: Write a function that takes model predictions and ground truth labels as input and returns the model's accuracy.\n",
    "\n",
    "    - Training Function: Implement a function that performs training on the given model using the AG_NEWS dataset. Your model should achieve an accuracy of at least 80% to get full marks for this part.\n",
    "\n",
    "    - Text Sampling: Write a function that takes a sample text as input and classifies it using your trained model.\n",
    "\n",
    "    - Confusion Matrix: Implement a function to display the confusion matrix for your model on the test data.\n",
    "\n",
    "    - Submission: Submit your completed Jupyter Notebook. Make sure to include a markdown cell at the beginning of the notebook that lists the names of all team members. Teams should consist of 3 to 4 members.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Evaluation Criteria:\n",
    "\n",
    "    - Correct setup of all the required libraries and modules (10%)\n",
    "    - Code Quality (30%): Your code should be well-organized, clearly commented, and easy to follow. Use also markdown cells for clarity. Comments should be given for all the provided code, this will help you understand its functionality.\n",
    "    \n",
    "   - Functionality (60%): \n",
    "        - All the functions should execute without errors and provide the expected outputs.\n",
    "        - RNN model class (20%)\n",
    "        - Accuracy fucntion (10%)\n",
    "        - Training function (10%)\n",
    "        - Sampling function (10%)\n",
    "        - Confucion matrix (10%)\n",
    "\n",
    "        - The model should achieve at least an 80% accuracy on the AG_NEWS test set for full marks in this criterion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de318da",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "https://pytorch.org/text/stable/datasets.html#text-classification\n",
    "\n",
    "https://paperswithcode.com/dataset/ag-news\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9801f9",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54394f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c pytorch torchtext\n",
    "# conda install -c pytorch torchdata\n",
    "# conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "878b524f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:20:31.657988Z",
     "start_time": "2023-10-29T21:20:28.901777Z"
    }
   },
   "outputs": [],
   "source": [
    "# The following libraries are required for running the given code\n",
    "# Please feel free to add any libraries you consider adecuate to complete the assingment.\n",
    "import numpy as np\n",
    "#PyTorch libraries\n",
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "# Dataloader library\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "# Libraries to prepare the data\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# neural layers\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# These libraries are suggested to plot confusion matrix\n",
    "# you may use others\n",
    "import scikitplot as skplt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bab55f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:20:32.531923Z",
     "start_time": "2023-10-29T21:20:32.520607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    # If using Mac M1/M2\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6583a711b675ed52"
  },
  {
   "cell_type": "markdown",
   "id": "3d38956d",
   "metadata": {},
   "source": [
    "### Get the train and the test datasets and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6b784",
   "metadata": {},
   "source": [
    "Classes:\n",
    "\n",
    "* 1 - World\n",
    "\n",
    "* 2 - Sports\n",
    "\n",
    "* 3 - Business\n",
    "\n",
    "* 4 - Sci/Tech\n",
    "\n",
    "We will convert them to:\n",
    "\n",
    "* 0 - World\n",
    "\n",
    "* 1 - Sports\n",
    "\n",
    "* 2 - Business\n",
    "\n",
    "* 3 - Sci/Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fbed19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:20:47.819626Z",
     "start_time": "2023-10-29T21:20:41.201114Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = AG_NEWS()\n",
    "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c372eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:20:49.043595Z",
     "start_time": "2023-10-29T21:20:49.012445Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the tokeniser\n",
    "# tokeniser object\n",
    "tokeniser = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data):\n",
    "    for _, text in data:\n",
    "        yield tokeniser(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794d0375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:20:53.825986Z",
     "start_time": "2023-10-29T21:20:50.939773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\"])\n",
    "#set unknown token at position 0\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48268d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:20:55.528003Z",
     "start_time": "2023-10-29T21:20:55.509873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'te3007'] [3314, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "#test tokens\n",
    "tokens = tokeniser('Welcome to TE3007')\n",
    "print(tokens, vocab(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c8f6a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:21:09.160823Z",
     "start_time": "2023-10-29T21:21:09.113359Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = int(len(train_dataset)*0.9)\n",
    "NUM_VAL = len(train_dataset) - NUM_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8290895e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:21:10.289694Z",
     "start_time": "2023-10-29T21:21:10.266497Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(train_dataset, [NUM_TRAIN, NUM_VAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc75b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:21:11.695471Z",
     "start_time": "2023-10-29T21:21:11.673561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108000 12000 7600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffdbf077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:21:18.613832Z",
     "start_time": "2023-10-29T21:21:18.584915Z"
    }
   },
   "outputs": [],
   "source": [
    "# function passed to the DataLoader to process a batch of data as indicated\n",
    "def collate_batch(batch):\n",
    "    # Get label and text\n",
    "    y, x = list(zip(*batch))\n",
    "    \n",
    "    # Create list with indices from tokeniser\n",
    "    x = [vocab(tokeniser(text)) for text in x]\n",
    "    x = [t + ([0]*(max_tokens - len(t))) if len(t) < max_tokens else t[:max_tokens] for t in x]\n",
    "\n",
    "    # Prepare the labels, by subtracting 1 to get them in the range 0-3\n",
    "    return torch.tensor(x, dtype=torch.int32), torch.tensor(y, dtype=torch.int32) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb459c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:21:24.011975Z",
     "start_time": "2023-10-29T21:21:23.994140Z"
    }
   },
   "outputs": [],
   "source": [
    "labels =  [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "max_tokens = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a55e6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T21:21:30.768990Z",
     "start_time": "2023-10-29T21:21:30.751004Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46b3794da5c0340c"
  },
  {
   "cell_type": "markdown",
   "id": "47b98898",
   "metadata": {},
   "source": [
    "### Let us build our RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(4,\n 'PalmOS Goes Linux PalmSource, the makers of the PalmOS are looking to acquire Chinas MobileSoft. MobileSoft will provide PalmSource with a solid footing in the lucrative Chinese and Asian markets, as well as providing valuable ')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T22:03:32.530260Z",
     "start_time": "2023-10-29T22:03:32.491012Z"
    }
   },
   "id": "9a98c22f574a8b0a"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(train_loader.dataset[0][1].split(' ')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T23:04:57.698968Z",
     "start_time": "2023-10-29T23:04:57.672788Z"
    }
   },
   "id": "163a21d4db651681"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9711085e382ae1cf"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50f20793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:54:38.708051Z",
     "start_time": "2023-10-29T22:54:38.686829Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 10 # complete\n",
    "NEURONS = 10# complete\n",
    "LAYERS = 10 # complete\n",
    "NUM_CLASSES = 4 # complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0f7f5621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T23:40:18.873492Z",
     "start_time": "2023-10-29T23:40:18.855251Z"
    }
   },
   "outputs": [],
   "source": [
    "class RnnModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden, layers, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.layers = layers\n",
    "        self.hidden = hidden\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=len(vocab), \n",
    "            embedding_dim=embed_size\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.RNN(10, hidden, layers, batch_first=True) \n",
    "        # complete this code/\n",
    "        # You may use PyTorch nn.GRU(), nn.RNN(), or nn.LSTM()\n",
    "        \n",
    "        self.fc = nn.Linear(hidden, num_classes) \n",
    "        # complete output classifier layer using linear layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.embedding_layer(x)\n",
    "        hidden = torch.zeros(self.layers, batch_size, self.hidden)\n",
    "        hidden = hidden.to(device=device, dtype=torch.float)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "        # implement forward pass. This function will be called when executing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2a42613f",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2023-10-30T00:13:35.167106Z",
     "start_time": "2023-10-30T00:13:35.132964Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    cost = 0.\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        for mb, (xi, yi) in enumerate(loader):\n",
    "            xi = xi.to(device=device, dtype = torch.long)\n",
    "            yi = yi.to(device=device, dtype = torch.long)\n",
    "            scores = model(xi)\n",
    "            cost += (F.cross_entropy(scores, yi)).item()\n",
    "            _, pred = scores.max(dim=1)\n",
    "            num_correct += (pred == yi.squeeze()).sum()\n",
    "            num_total += pred.size(0)\n",
    "\n",
    "    return cost/mb, float(num_correct)/num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0069470405578613\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2 - t1)\n",
    "print(type(t2-t1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T00:04:22.862633Z",
     "start_time": "2023-10-30T00:04:20.855334Z"
    }
   },
   "id": "341b9aa9a04d62b1"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5e843e1f",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2023-10-30T00:13:40.334785Z",
     "start_time": "2023-10-30T00:13:40.309249Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimiser, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    train_cost = 0.\n",
    "    val_cost = 0.\n",
    "    \n",
    "    print(\"## Total number of batches: {}\".format(len(train_loader)))\n",
    "    \n",
    "    last_batch_time = 1\n",
    "    remaining_batches = -1\n",
    "    remaining_epochs = epochs\n",
    "    batches = len(train_loader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_correct_num  = 0.\n",
    "        train_total = 0.\n",
    "        train_cost_acum = 0\n",
    "        remaining_batches = batches\n",
    "        for mb, (xi, yi) in enumerate(train_loader):\n",
    "            print(\"\\r## Epoch {}/{} ..... Batch {}/{} ..... Epoch ETA {} ..... Training ETA {}\".format(\n",
    "                epoch + 1, \n",
    "                epochs, \n",
    "                mb + 1, \n",
    "                batches,\n",
    "                datetime.timedelta(\n",
    "                    seconds=int(remaining_batches * last_batch_time)\n",
    "                ),\n",
    "                datetime.timedelta(\n",
    "                    seconds=int(\n",
    "                        (remaining_batches * last_batch_time) + ((remaining_epochs - 1) * batches * last_batch_time)\n",
    "                    )\n",
    "                )\n",
    "            ), end=\"\")\n",
    "            t1 = time.time()\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.long)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
    "            optimiser.zero_grad()\n",
    "            cost.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            train_correct_num += (torch.argmax(scores, dim=1) == yi.squeeze()).sum()\n",
    "            train_total += scores.size(0)\n",
    "\n",
    "            train_cost_acum += cost.item() \n",
    "            t2 = time.time()\n",
    "            last_batch_time = t2 - t1\n",
    "            remaining_batches -= 1\n",
    "\n",
    "        val_cost, val_acc = accuracy(model, val_loader)\n",
    "        train_acc = float(train_correct_num)/train_total\n",
    "        train_cost = train_cost_acum/mb\n",
    "        remaining_epochs -= 1\n",
    "        \n",
    "        print(\"\\r## Epoch {}/{} ... Train Cost {:.6f} ... Val Cost {:.6f} ... Train Acc {:.6f} ... Val Acc {:.6f}\".format(\n",
    "            epoch + 1, epochs,\n",
    "            train_cost, val_cost,\n",
    "            train_acc, val_acc\n",
    "        ))\n",
    "\n",
    "        #print(f'Epoch:{epoch}, train cost: {train_cost:.6f}, val cost: {val_cost:.6f},'\n",
    "        #          f' train acc: {train_acc:.4f}, val acc: {val_acc:4f},'\n",
    "        #          f' lr: {optimiser.param_groups[0][\"lr\"]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "87775b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T00:13:43.479214Z",
     "start_time": "2023-10-30T00:13:43.451312Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10 # define\n",
    "lr = 0.01 # to do\n",
    "# instantiate model\n",
    "rnn_model = RnnModel(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES)\n",
    "optimiser = torch.optim.Adam(rnn_model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aec12a1b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T01:01:22.703939Z",
     "start_time": "2023-10-30T00:13:44.160300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Total number of batches: 422\n",
      "## Epoch 1/10 ... Train Cost 1.391132 ... Val Cost 1.416355 ... Train Acc 0.250685 ... Val Acc 0.258583\n",
      "## Epoch 2/10 ... Train Cost 1.390176 ... Val Cost 1.416866 ... Train Acc 0.249944 ... Val Acc 0.244833\n",
      "## Epoch 3/10 ... Train Cost 1.390463 ... Val Cost 1.416354 ... Train Acc 0.251926 ... Val Acc 0.258583\n",
      "## Epoch 4/10 ... Train Cost 1.389895 ... Val Cost 1.417962 ... Train Acc 0.248435 ... Val Acc 0.244833\n",
      "## Epoch 5/10 ... Train Cost 1.390352 ... Val Cost 1.416656 ... Train Acc 0.252231 ... Val Acc 0.245500\n",
      "## Epoch 6/10 ... Train Cost 1.389971 ... Val Cost 1.416232 ... Train Acc 0.250250 ... Val Acc 0.258583\n",
      "## Epoch 7/10 ... Train Cost 1.389941 ... Val Cost 1.416312 ... Train Acc 0.249361 ... Val Acc 0.258583\n",
      "## Epoch 8/10 ... Train Cost 1.389937 ... Val Cost 1.416463 ... Train Acc 0.249593 ... Val Acc 0.251083\n",
      "## Epoch 9/10 ... Train Cost 1.392536 ... Val Cost 1.429499 ... Train Acc 0.249593 ... Val Acc 0.251083\n",
      "## Epoch 10/10 ... Train Cost 1.392864 ... Val Cost 1.420675 ... Train Acc 0.249898 ... Val Acc 0.245500\n"
     ]
    }
   ],
   "source": [
    "train(rnn_model, optimiser=optimiser,  epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a3ef175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:53:19.350438Z",
     "start_time": "2023-10-29T22:53:19.200269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.5100e+02, 3.4600e+02, 3.5100e+02,  ..., 1.6700e+02, 1.0000e+00,\n",
      "         4.4000e+01],\n",
      "        [1.1830e+03, 3.6400e+03, 6.6000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0100e+02, 4.0000e+00, 6.1200e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.5890e+03, 1.2900e+02, 6.3010e+03,  ..., 2.8810e+03, 1.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.3900e+02, 5.6850e+03, 3.7200e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2800e+02, 9.4300e+02, 6.6000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got MPSFloatType instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy(rnn_model,\u001B[38;5;250m \u001B[39mtest_loader)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[22], line 11\u001B[0m, in \u001B[0;36maccuracy\u001B[0;34m(model, loader)\u001B[0m\n\u001B[1;32m      9\u001B[0m xi \u001B[38;5;241m=\u001B[39m xi\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice, dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     10\u001B[0m yi \u001B[38;5;241m=\u001B[39m yi\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice, dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m---> 11\u001B[0m scores \u001B[38;5;241m=\u001B[39m model(xi)\n\u001B[1;32m     12\u001B[0m cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (F\u001B[38;5;241m.\u001B[39mcross_entropy(scores, yi))\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     13\u001B[0m _, pred \u001B[38;5;241m=\u001B[39m scores\u001B[38;5;241m.\u001B[39mmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[27], line 25\u001B[0m, in \u001B[0;36mRnnModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     23\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(x)\n\u001B[0;32m---> 25\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_layer(x)\n\u001B[1;32m     26\u001B[0m hidden \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers, batch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden)\n\u001B[1;32m     27\u001B[0m out, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn(x, hidden)\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39membedding(\n\u001B[1;32m    163\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_norm,\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_type, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_grad_by_freq, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparse)\n",
      "File \u001B[0;32m~/.conda/envs/Finance/lib/python3.11/site-packages/torch/nn/functional.py:2233\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2227\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2228\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2229\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2230\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2231\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2232\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2233\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39membedding(weight, \u001B[38;5;28minput\u001B[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got MPSFloatType instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy(rnn_model, test_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed30693d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:53:21.227999Z",
     "start_time": "2023-10-29T22:53:21.212982Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_text(model, loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "534f0220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:53:22.073049Z",
     "start_time": "2023-10-29T22:53:22.062583Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_text(rnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d73f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327e204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc921f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed62b0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
